\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}
\phantomsection
% \markboth{Introduction}{Introduction}
%
% New sequencing technologies are producing more and more biological data,
% including genomic sequences of many species. Therefore it is important to
% develop tools for automated analysis of such data. In this thesis we focus on
% computational methods for sequence annotation and sequence alignment.  In the
% sequence annotation problem, we want to label parts of the sequences according
% to their function, or meaning. We call
% such a labeling an \firstUseOf{annotation}. For example,  we
% can label each symbol of a genomic sequence base on whether it is part of a
% gene or not as in the following example ($g$ is a label representing genes and $n$ is a label for non-gene parts).
% \begin{verbatim}
% Sequence:     ACGGTGCGTTAGCTGCTCTGATGTCTTCGATCTAGCTAGT
% Annotation:   nnnnnnnngggggggggggggggggggnnnnnnnnnnngg
% \end{verbatim}
% The \firstUseOf{sequence alignment} is a data structure
% that characterizes similarity or shared origin of two or more sequences.
% We insert gap symbols (dashes) so that corresponding parts of the sequence are in the same column as in the following
% example.
% \begin{verbatim}
% Sequence X:   CTGCTAGCTACGT--GTGT
% Sequence Y:   ---------ACGTGGAT--cp
% \end{verbatim}
% Both annotation and alignment are fundamental bioinformatics problems.
% The first stages of analysis of newly
% sequences genomes typically include aligning it with the genomes of related
% species (that is already sequenced), and searching for known structures (like genes) inside
% new genomes.
% Many subsequent methods for analysing genomes rely on sequence
% annotation and alignment. To avoid artefacts in the results of
% these downstream methods, there is need to develop algorithms for producing sequence
% annotation and alignment with as low error rate as possible.
% Tools for both
% sequence annotation and alignment are often based on hidden Markov models (HMMs)
% \cite{Durbin1998,Alexanderson2004,Brejova2005, FEAST2011,Krogh2001,Majoros2005,
% Meyer2002,Nanasi2010,Pairagon2009, Schultz2006,Kovac2012,Pachter2002,
% Liu2010,Brown2010, Lunter2008}.  In this thesis we propose new techniques for
% use of HMMs  in these domains and also give proofs of NP-hardness for several related problems.
%
% We work with generative probabilistic models, \abbreviation{hidden Markov
% Models}{HMM} and their variants. In general, an HMM is a state machine that
% generates a sequence (string) along with a sequence of states (called state path).
% Since an HMM is a probabilistic model,
% it also defines the probability of sequences and state paths. The state
% path contains information about the structure of the generated sequence. In
% practice we are often given the generated sequence and the state path is hidden. The
% goal of the decoding algorithm is to reverse the generation process and obtain
% the original state path or at least its approximation.
%
% When using HMMs for annotation of biological sequences, we construct the
% HMM so  that the structure of the states corresponds to the biological features we
% are interested in.
% Each feature can be encoded in one or several states.  Then we assume that the genomic sequence of interest was generated by our model and use a decoding
% algorithm to obtain a state path which is as close as possible to the true
% state path. The Viterbi algorithm
% \cite{Durbin1998} is traditionally used for decoding, but other optimization criteria can be used to obtain more
% accurate results \cite{Brown2010, Gross2007, Nanasi2010, Truszkowski2011}. Note that
% accuracy measures may depend on the application domain.  In Chapter
% \ref{CHAPTER:TWOSTAGE} we study a special type of decoding algorithms: two-stage
% algorithms. In the first stage, the algorithm infers important aspects of
% the annotation and in the second stage it fills remaining details in a way
% consistent with the first-stage results.  We show that  two-stage
% algorithms can improve the accuracy of decoding (as far we know, such
% algorithms were previously used only for reducing the running time). We also
% study the computational complexity of several decoding criteria appropriate for
% the first stage and we show NP-hardness results for obtaining the optimal
% annotations using these criteria. Namely we study the most probable footprint
% problem, the most probable set problem and the most probable restriction
% problem.
%
% In sequence alignment, the goal is to search for
% corresponding  parts of the sequences and arrange them into same position in the
% alignment.  To choose the biologically correct alignment, we usually optimize some
% scoring scheme. We will consider scoring schemes which are  defined using
% \abbreviation{pair hidden Markov models}{pHMM}. A pHMM generates pairs of
% sequences along with their alignment (an alignment is defined by the state
% path).  This model is an extension of HMM.
%
%
% In the fourth chapter we propose a tractable method for aligning sequences with
% tandem repeats. A tandem repeat consists of consecutive copies (not exact) of a
% certain motif (short genomic sequence). Tandem repeats cause problems with
% sequence alignments because it is hard to distinguish between individual copies of the motif.
% We extend a traditional pHMM model for sequence alignment by additional states
% modeling tandem repeats. We also propose new decoding algorithms tailored to
% this model. We show on simulated data that our new model and decoding methods
% decrease the error rate, and with a particular increase of accuracy near the border of tandem repeats.
%
\todo{chceme aj celu minimovku nejak zhrnut a dat motivaciu k tym repeatom}
