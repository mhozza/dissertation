\chapter{Thesis Project}

\todo{intro co tu bude}

\section{Estimating the coverage and size of the genome}

We developed a tool for estimating the genome size from low coverage erroneous sequencing data, called CovEst, which we have described in Chapter~\ref{chap:genomesize}. We published and presented CovEst on SPIRE 2015 conference\cite{covest}.

The tool is just a prototype and various issues need to be fixed prior the final version. Most importantly the model parameters finding algorithm speed have to be improved. Also more complex models can be added. Finally, we can make the algorithm more robust by increasing the independence of the data, or using multiple \kmer\ histograms.

\paragraph{Parameter estimation algorithm improvements.}
In the current version, we use the L-BFGS-B\cite{l-bfgs-b} algorithm for parameter estimation, with fine-tuning using the grid search.
The L-BFGS-B algorithm often fails to find the locally maximal likelihood, therefore a fine tuning is needed.

The grid search algorithm, is a local search algorithm, which searches the parameter grid of depth $G$, with step $S$ around the actual parameter vector, i.e.\ if we have 5 parameters $P = p_1\dots p_5$ and $G = 3$, the grid of parameters would be $\{p_1 S^{-3}, p_1 S^{-2}, \dots, p_1 S^3\} \times \cdots \times \{p_5 S^{-3}, \dots, p_5 S^3\}$. We can omit the current parameter vector from the grid. The size of the grid is ${(2G)}^P - 1$ and increases exponentially with increasing parameter count. The algorithm is iterative and the step decreases if the previous iteration was unable to find better enough parameters. Once the step size is too small, the algorithm stops.

In our test algorithm needed several thousand iterations and the large grid size made the algorithm very slow. If we would like to add some parameters into the model, the algorithm would soon be unusable. Therefore we would like avoid the fine-tuning.

This can be done in several ways. We can either try to fix the L-BFGS-B algorithm to always find the local maximum (if it is possible), or replace it by better optimization algorithm. The other option is to use expectation maximization algorithm instead of direct optimizing the likelihood, similarly to the~\cite{waterman}.

\paragraph{The model improvements.}
The most complex model in our tool is the repeat model (see Chapter~\ref{chap:genomesize}). The model includes simple repeat modeling and has 5 parameters: the coverage $c$, the error rate $\epsilon$ and three repeat parameters $q_1, q_2, q$.

We can add more complex repeat modeling, similarly to the~\cite{williams}. We can also model other properties of the sequencing data, e.g.\ polymorphisms.

\paragraph{The algorithm robustness improvements.}

We estimate the parameters from single \kmer\ histogram. It is also possible to build several \kmer\ histograms for different $k$. Estimating parameters from multiple histograms can avoid some artifacts or biases that may be introduced by a particular $k$ and improve the precision of the algorithm providing more data.

Moreover the \kmers\ in histogram are not completely independent. Each \kmer\ is shares some sequence with $k-1$ other consecutive \kmers. We may alter this dependence using spaced $k$-mers, i.e\ we omit some positions in the \kmer.
The mask for the spaced \kmers\ can by chosen randomly for a single run of the \kmer\ counting algorithm. We can also build multiple histograms using multiple \kmer\ masks.

\section{Repeats and gene families}\label{sect:repeats-families}

\todo{chceme to nejak spojit}
\todo{evolucia repeatov}
\todo{rodiny z readov}
\todo{zakomponovat rozdelenie do BD modelu namiesto exaktnych cisel}
