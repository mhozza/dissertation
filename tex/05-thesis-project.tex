\chapter{Thesis Project}

In this chapter we present our plans for the dissertation thesis. The thesis will consist of two main topics:
the coverage and genome size estimation, and finding and evolution of repeats and gene families.
We will summarize the current status and problems.

\section{Estimating the Coverage and Size of the Genome}

We developed a tool for estimating the genome size from low coverage erroneous sequencing data, called CovEst, which we have described in Chapter~\ref{chap:genomesize}. We published and presented CovEst on SPIRE 2015 conference\cite{covest}.

The tool is just a prototype and various issues need to be fixed prior the final version. Most importantly the model parameters finding algorithm speed have to be improved. Also more complex models can be added. Finally, we can make the algorithm more robust by increasing the independence of the data, or using multiple $k$-mer histograms.

\paragraph{Parameter estimation algorithm improvements.}
In the current version, we use the L-BFGS-B\cite{l-bfgs-b} algorithm for parameter estimation, with fine-tuning using the grid search.
The L-BFGS-B algorithm often fails to find the locally maximal likelihood, therefore a fine tuning is needed.

The grid search algorithm, is a local search algorithm, which searches the parameter grid of depth $G$, with step $S$ around the actual parameter vector, i.e.\ if we have 5 parameters $P = p_1\dots p_5$ and $G = 3$, the grid of parameters would be $\{p_1 S^{-3}, p_1 S^{-2}, \dots, p_1 S^3\} \times \cdots \times \{p_5 S^{-3}, \dots, p_5 S^3\}$. We can omit the current parameter vector from the grid. The size of the grid is ${(2G)}^P - 1$ and increases exponentially with increasing parameter count. The algorithm is iterative and the step decreases if the previous iteration was unable to find better enough parameters. Once the step size is too small, the algorithm stops.

In our test algorithm needed several thousand iterations and the large grid size made the algorithm very slow. If we would like to add some parameters into the model, the algorithm would soon be unusable. Therefore we would like avoid the fine-tuning.

This can be done in several ways. We can either try to fix the L-BFGS-B algorithm to always find the local maximum (if it is possible), or replace it by better optimization algorithm. The other option is to use expectation maximization algorithm instead of direct optimizing the likelihood, similarly to the~\cite{waterman}.

\paragraph{The model improvements.}
The most complex model in our tool is the repeat model (see Chapter~\ref{chap:genomesize}). The model includes simple repeat modeling and has 5 parameters: the coverage $c$, the error rate $\epsilon$ and three repeat parameters $q_1, q_2, q$.

We can add more complex repeat modeling, similarly to the~\cite{williams}. We can also model other properties of the sequencing data, e.g.\ polymorphisms.

\paragraph{The algorithm robustness improvements.}

We estimate the parameters from single $k$-mer histogram. It is also possible to build several $k$-mer histograms for different $k$. Estimating parameters from multiple histograms can avoid some artifacts or biases that may be introduced by a particular $k$ and improve the precision of the algorithm providing more data.

Moreover the $k$-mers in histogram are not completely independent. Each $k$-mer is shares some sequence with $k-1$ other consecutive $k$-mers. We may alter this dependence using spaced $k$-mers, i.e\ we omit some positions in the $k$-mer.
The mask for the spaced $k$-mers can by chosen randomly for a single run of the $k$-mer counting algorithm. We can also build multiple histograms using multiple $k$-mer masks.

\section{Repeats and Gene Families}\label{sect:repeats-families}

In Chapter~\ref{chap:repeatsfamilies} we presented various methods for finding repeats. We also presented a model for gene family evolution.
In our dissertation thesis we would like to blend these two concepts.

Firstly we would like to adjust the methods for the de novo repeat finding in reads to develop a method for finding the gene families from the reads.
We do not expect to be able to find exact gene family counts form the reads only, therefore we also want to adjust the birth death model to work with the probabilistic distributions of the family counts.

Secondly, we would like to adjust the birth death model to work with large repeat counts, so we can estimate the evolution of the repeat families. The large counts of the repeats in contrast to the gene families may cause computational problems in the model. For example, we would need to select the root family size for wider range. However, with such high counts in the repeats we may decrease the precision of the algorithm in order to overcome these issues.
