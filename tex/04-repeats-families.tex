\chapter{Repeats and Gene Families}\label{chap:repeatsfamilies}

Although, repeats and gene families are both DNA sequences which appears multiple times in the genome, they differ in copy number, function and creation process.

Repeats usually does not have any function and are often represented by several thousands of copies\cite{cell}. They are classified into multiple classes depending on their size and how they replicate.
\emph{Simple sequence repeate} consists of tandem arrays of up to thousands of copies of short sequences, ranging from 1 to 500 nucleotides.
\emph{Retrotransposons} are capable of moving to different sites in DNA by the reverse transcription.
\emph{DNA transposons} moves through the DNA by being copied and reinserted as DNA sequences\cite{cell}.

The gene families are groups of related genes. They arise by duplication of an ancestral gene. The different members of the families diverge due to mutations during the evolution. Some of the mutations may result in loss of ability to produce a functional gene product. The nonfunctional gene copies are called \emph{pseudogenes}.
Gene duplications can arise by two mechanisms: duplication of a segment of DNA, or by reverse transcription of an mRNA, followed by integration of the cDNA copy into a new chromosomal site.
Duplication by reverse transcription usually yields an inactive gene copy (\emph{processed pseudogene}).
The copy number of gene families is much lower than in repeats.

As the repeats and gene families consists of multiple very similar sequences in DNA, they cause problems in DNA assembly and sequencing data analysis. NGS provides a large amount of short sequences from DNA (reads). Repetitive sequences are usually longer than reads, and therefore reads from various positions of the same repetitive DNA are very hard to distinguish, which makes hard to determine the size of the repetitive sequence.

Repetitive sequences forms a substantial part of DNA. For example,
transposable elements forms more then 70\% of the genome in some plants and amphibians, and 45\% in human genome\cite{biemont2006genetics}.
Therefore studying repetitive sequences is one of the essential tasks in DNA analysis.

In this chapter we will present multiple approaches for detecting repetitive sequences and their copy numbers in several scenarios.

% (1) v uvode moze byt strucny popis co su repeaty a genove rodiny z biologickeho hladiska a preco sposobuju problemy pri assembly

\section{Finding Tandem Repeats}
Tandem repeats are repeats which occurs consequently one after another. There are many tools for finding tandem repeats in the assembled genome, e.g.\ Tandem repeats finder\cite{trf}, ATR\cite{atr}, TANTAN\cite{tantan} and Sunflower model\cite{nanasi2014probabilistic}.

In this section we will briefly present the main idea used in tandem repeats finder.

The tandem repeats finder algorithm consists of two components: detection component, which detects possible tandem repeat candidates, and analysis component, which analyses the candidates to filter actual tandem repeats.

The detection algorithm looks for exactly matching \kmers which are separated by $d$ nucleotides ($d$ is not specified in advance). It keeps a list of all possible \kmers (probes).
For each probe $p$ it stores a history list $H_p$.
When a particular position $i$ is added to the $H_p$, for all previous positions $j$ in $H_p$, $d = i - j$ becomes a possible pattern size.
The algorithm also maintains a distance list $D_d$, which is basically a sliding window of length $d$ and tracks the positions of all matches and their total. The distance list is updated every time a match at distance $d$ is detected. The updates sets right end of the window to $i$ and matches before $j = i - d$ are dropped from $D_d$ and subtracted from the total. The information in $D_d$ is then tested using statistical tests and if it passes, it is passed to analysis component of the algorithm.

In analysis, the pattern consisting of positions $j+1\dots i$ is selected and aligned with the surrounding sequences using wraparound dynamic programming\cite{fischetti1992apostolico, myers1989approximate}. If at least two copies are aligned, the tandem repeat is reported.

The more details on the statistical criteria and indel handling can be found in~\cite{trf}. There are also other approaches to tandem repeat finding, e.g.\ based on Hidden Markov models (\cite{tantan, nanasi2014probabilistic}).

Next, we will focus mainly on interspersed repeats, which copies in contrast to the tandem repeats appears on random positions in the genome.

\section{Finding the Known Repeats and Families in Assembled Genome}

The known repeats and families are stored in several databases. Some examples of repeat databases are repbase\cite{repbase}, dfam\cite{dfam}, and example of the gene family databases is pfam\cite{pfam}.

There are two approaches for sequence finding. The first one is based on sequence similarity, which is computed by sequence alignment. The second one is based on profile hidden Markov models.

\paragraph{}
\todo{co je local alignment}
The standard algorithms for local alignment of 2 sequences look for the optimal local alignment according to some scoring scheme. They use a dynamic programming algorithm to find the optimal alignment. The time complexity of this approach is proportional to the product of the lengths of both sequences, which makes this approach very slow for long sequences.

Therefore there have been developed heuristic algorithms, which find alignments much faster, but may miss the best alignment in some circumstances. One of such algorithm is BLAST\cite{blast}.
BLAST firstly looks for exact matches of length $T$, called seeds.
Each seed is then extended to maximize the score. The standard BLAST algorithm searches only for gapless alignments (i.e.\ it does not consider any indels), but there are versions which also enables gaps in the alignment.

\paragraph{}
\todo{co je HMM?}
The repeat or gene family consist of set of sequences assigned to the family. The particular sequences may differ due to mutations acquired during the evolution. This may be substitution, insertion, or deletion of one or more nucleotides. The profile HMM have to take into account all this mutation and return higher probability for the sequences belonging to the family, than for other sequences.
Assume, we have a multiple alignment of sequences from the family. The profile HMM\cite{profile-hmm} contains a sequence of $M$ states (match states), corresponding to matching positions in the alignment. Each state $m_k,\, 1 \leq k \leq M$, have a distinct emission distribution.
For each matching state $m_k$ there is a delete state $d_k$, which does not produce any nucelotide and allows to skip any nucleotide. Finally there are $M+1$ insert states, which allows to insert any sequence before or after any nucleotide. For convinience, the dummy starting state $m_0$ and ending state $m_{M+1}$ is added.
The architecture of the model can be seen in figure~\ref{fig:profile-hmm}. The probability distributions are trained from the training sequences. See~\cite{profile-hmm} for more details.
\todo{obrazok}

Once a model is built it can be used for search. The search involves a local alignment of the profile HMM to the sequence.
There are various dynamic programming algorithms for performing the alignment. The standard algorithm for inferring in HMM is the Viterbi algorithm, which is very slow comparing to sequnece alignment method\cite{eddy2011accelerated}. Recently published algorithm, HMMER3\cite{eddy2011accelerated}, for the alignment uses multiple segment Viterbi algorithm\cite{eddy2011accelerated}, which enables fast computation of an optimal sum of multiple ungapped local
alignment segments. This can be used as heuristic filter before running the full algorithm.

There are various tools for finding repeats and gene families, implementing these methods.
The most used ones are repeat masker\cite{repeatmasker}, interproscan\cite{mitchell2015interpro}, HMMER\cite{eddy2011accelerated}.

% (2) dalsia cast sa tyka detekcie znamych repeatov a znamych rodin v uz poskladanych genomoch (pripadne by sa dalo aj v jednotlivych readoch, ale bolo by to pomerne pomale)
% - tu mozes spomenut databazy znamych repeatov, napr repbase, dfam a rodin napr. pfam
% - a hladanie zalozene cisto na podobnosti sekvencii (BLAST a spol) a na profilovych HMM
% - oblubene nastroje su napr. repeatmasker http://repeatmasker.org/, interproscan, HMMER
% - tieto veci staci pomerne strucne vysvetlit, bez velkych detailov

\section{De Novo Repeat Finding}

\todo{intro to repeats - depends on what will be in general intro}
% (3) dalsia cast by mohla byt o hladani repeatov, ktore este nie su zname (de novo discovery)
% - tu mozes zacat s programami, ktore to hladaju v poskladanom genome, napr RepeatScout pripadne dalsie
% - potom spomen pristupy, ktore pracuju z readov, pri nizsom pokryti - to je to, co si zrejme zacal pisat a tu sa da strucne spravit aj odvolavka na programy z kapitoly 3
\subsection{Finding de Novo Repeats in assembled genome}

\subsection{Finding Repeats by K-mer abundance histogram analysis}

\todo{odvolat sa na kapitolu 3, pripadne spomenut advanced algoritmus z \cite{waterman}}

\subsection{Partial Sequence Assembly}

As we mentioned in section \ref{sec:kmerhist}, we can look at the NGS sequencing as a random sampling process. We select a random position in the genome and read $N$ bases starting that position, where $N$ is the length of a read. We do this many times depending on target coverage.
Repetitive sequences have multiple copies in a genome, so we expect more occurrences of repetitive sequences than single-copy sequences in the sequencing data. If the coverage is low, there will be very few single copy sequences in the data and the chance that two of them are overlapping is very low. On the contrary the average coverage of repetitive sequences will be higher and the chance of overlapping repetitive sequences will be higher.

The \emph{partial sequence assembly} method works as follows: As an input we take low coverage NGS sequencing data. Using assembly algorithms, we assemble the data into contigs. We take into account only contigs, which consists of at least $m$ reads. The appropriate value can be computed from the coverage. The number of contigs, $M$, expected containing a number of reads $j$ is given by equation\cite{swaminathan2007global}:
$$E(M) = Ne^{-2c\sigma}(1-e^{c\sigma})^{j-1}$$
$$\sigma = 1 - \frac{T}{L},$$
where $c$ is the coverage, $L$ is the read length, and $T$ the base pair overlap required for contig formation.

The estimated copy number, $C$, within any sequence window was then calculated by\cite{swaminathan2007global}:
$$C = \frac{o}{e}$$
$$e = \frac{cw}{L},$$
where $o$ represents the observed number of reads matching in the sequence window, $e$ represents the expected number of reads matching a single copy sequence window of size $w$, $c$ is the coverage, and $L$ is the read length.

This method allows simple repeat analysis of low coverage sequencing data, which is especially useful in analysis of large genomes e.g.\ plant genomes. This method was successfully used for repeat analysis of soybean (\textit{Glycine max}) from $0.07\times$ coverage sequencing data\cite{swaminathan2007global}.
However, this method suffers from several drawbacks. The major drawback is that larger repeats can be split into multiple sequences. In addition, it depends on slow assembly process.

\subsection{Sequencing Data Clustering}

The other approach to de novo repeat detection and analysis is \emph{sequencing data clustering}. The goal is to separate sequences into multiple groups, where each group consists of similar sequences.
The key data structure for such clustering is a graph, where reads are vertices, and edges are between similar sequences. The edges can be labeled by the similarity score. Such graph can be constructed by performing all-to-all pairwise comparisons and recording all read pairs with sequence overlaps exceeding a specified treshold\cite{pertea2003tigr, novak2010graph}. \todo{spomenut mgblast?}

The basic method of clustering the graph is to split it by connected components. The granularity of such graph strongly depends on sequence coverage. The higher the coverage is, the smaller number and bigger clusters will be found in the graph. Additionally, this methods may merge multiple independent repeats into one cluster. This is caused by so called bridge reads, which are similar to multiple repetitive sequences. This method is used in \emph{tclust}\cite{pertea2003tigr}.

The issues of the basic method can be fixed by more clever clustering algorithm --- \emph{hierarchical aglomeration}. The aim of hierarchical alglomeration is to split the graph into clusters (communities) which are more connected inside as outside the component. The metrics used for evaluating of the property is \emph{modularity}.
The modularity $Q$ denotes the frequency of edges within a community in respect to the expected number of edges in random graph. It can be masured as:
$$Q = \frac{1}{2m}\sum\left[A_{ij}-\frac{k_i k_j}{2m}\right] \delta(c_i c_j),$$
where $k_i,\, k_j$ are the degrees of the vertices $i,\,j$, $m$ is the overall number of edges in the graph, $A_ij$ is one if $i$ and $j$ are neighbors and zero otherwise, and $\delta(c_i, c_j)$ is one if comunity $c_i = c_j$.
We want to find the clustering with maximal modularity.
\todo{greedy algorithm}

\todo{citations}

\todo{figures}

\subsection{Conclusion}

\todo{conclusion}

% \todo{clanky:}
% \begin{itemize}
%   \item \cite{gu2008identification}
%   % \item \cite{sveinsson2013transposon} - blbost
%   \item \cite{shapiro2005repetitive}
% \end{itemize}

% Velmi zhruba o com to ma asi byt
% - nejake problemy a ako ich riesit - dat je vela, da sa spravit nizsie pokrytie (aj random samplovanim)
% - vlastnosti repeatov - je ich viac ako beznych sekvencie - teda ked nahodne sekvenujeme, tak ocakavame ze tam bude viac podobnych sekvencii ktore zodpovedaju repeatu ako podobnych co zodpovedaju nerepeatu (repeaty maju ako keby vacsi coverage)
% - ked znizujeme pokrytie, znizujeme pravdepodobnost ze sa dany kus sekvencii vyskytne v datach. kedze repeatov je viac, tak tie maju vyssiu pravdepodobnost ze sa dostanu do dat, cize vieme pokrytie nastavit tak, aby to co ostane v datach boli s vysokou pravdepodobostov repeaty, a s vysokou pravdepodobnostou sa tam dostanu vsetky (resp ocakavame ze sa ich tam dostane dost velka cast)
% niekolko metod:
% - urobit ciastocne assembly a zobrat kontigy (tiez nastudovat)
% - nastavit pokrytie dost nizko a detegovat komponenty suvislosti (tclust, nastudovat)
% - grafove klastrovanie\cite{novak2010graph} -> pisu ze celkom sikovne
% - spomenut rozdieli oproti modelovaniu repeatov z predoslej kapitoly

\section{Evolution of Gene Families}
\todo{intro to gene families - depends on what will be in general intro}
% (4) posledna cast by bola o evolucii velkosti genovych rodin (s tym, ze modely a postupy by sa dali pouzit aj na repeaty, pripadne pohladaj, ci to niekto robil)

\todo{clanky:}
\begin{itemize}
  \item \cite{hahn2005estimating}
\end{itemize}

\todo{conclusion}

\section{Conclusion}
\todo{conclusion}
